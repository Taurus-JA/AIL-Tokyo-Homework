{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. Theanoを用いて, MNISTを畳み込みニューラルネットワーク(CNN)で学習せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- homework関数を完成させて提出してください\n",
    "    - 訓練データはtrain_X, train_y, テストデータはtest_Xで与えられます\n",
    "    - train_Xとtrain_yをtrain_X, train_yとvalid_X, valid_yに分けるなどしてモデルを学習させてください\n",
    "    - test_Xに対して予想ラベルpred_yを作り, homework関数の戻り値としてください\\\n",
    "- pred_yのtest_yに対する精度(F値)で評価します\n",
    "- 全体の実行時間がiLect上で60分を超えないようにしてください\n",
    "- homework関数の外には何も書かないでください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のような内容のコードが**事前**に実行されます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                           mnist.target.astype('int32'),\n",
    "                           random_state=42)\n",
    "\n",
    "mnist_X = mnist_X / 255.0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=??)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルのhomework関数を完成させて提出してください\n",
    "- **上記のコード以外で必要なもの**は全て書いてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "ilect": {
     "is_homework": true
    }
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    \n",
    "    train_y = np.eye(10)[train_y]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, 28, 28))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, 28, 28))\n",
    "\n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y,\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=42)\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convolutional layer\n",
    "    class Conv:\n",
    "        # Constructor\n",
    "        def __init__(self, filter_shape, function, border_mode=\"valid\",\n",
    "                     subsample=(1, 1)):\n",
    "            # filter shape (k, l, i, j): 4次元\n",
    "            self.filter_shape = filter_shape\n",
    "            self.function = function\n",
    "            self.border_mode = border_mode\n",
    "            self.subsample = subsample\n",
    "\n",
    "            self.W = theano.shared(np.random.uniform(low=-0.08, high=0.08,\n",
    "                                               size = self.filter_shape\n",
    "                                               ).astype('float32'), name='W')\n",
    "            self.b = theano.shared(np.zeros(self.filter_shape[0],).astype('float32'),\n",
    "                                   name='b') \n",
    "        \n",
    "            self.params = [self.W, self.b] \n",
    "\n",
    "        # Forward Propagation\n",
    "        def f_prop(self, x):\n",
    "            conv_out = conv2d(x, self.W, border_mode= self.border_mode, subsample=self.subsample) \n",
    "            self.z = self.function(conv_out + self.b[np.newaxis, :, np.newaxis, np.newaxis]) \n",
    "            return self.z\n",
    "        \n",
    "    class Pooling:\n",
    "        # Constructor\n",
    "        def __init__(self, pool_size=(2, 2), mode='max'):\n",
    "            self.pool_size = pool_size\n",
    "            self.mode = 'max'\n",
    "            self.params = []\n",
    "\n",
    "        # Forward Propagation\n",
    "        def f_prop(self, x):\n",
    "            return pool.pool_2d(input=x, ds=self.pool_size, mode=self.mode, ignore_border=True)  \n",
    "        \n",
    "    class Flatten:\n",
    "        # Constructor\n",
    "        def __init__(self, outdim=2):\n",
    "            self.outdim = outdim\n",
    "            self.params = []\n",
    "\n",
    "        # Forward Propagation\n",
    "        def f_prop(self, x):\n",
    "            return T.flatten(x, self.outdim)\n",
    "    \n",
    "    class Layer:\n",
    "        # Constructor\n",
    "        def __init__(self, in_dim, out_dim, function, possibility):\n",
    "            self.in_dim = in_dim\n",
    "            self.out_dim = out_dim\n",
    "            self.function = function\n",
    "            self.possibility = possibility\n",
    "            self.W = theano.shared(np.random.uniform(\n",
    "                        low=-np.sqrt(6. / (in_dim + out_dim)),\n",
    "                        high=np.sqrt(6. / (in_dim + out_dim)),\n",
    "                        size=(in_dim, out_dim)\n",
    "                        ).astype(\"float32\"), name=\"W\")\n",
    "            self.b = theano.shared(np.zeros(out_dim).astype(\"float32\"), name=\"b\")\n",
    "            self.params = [self.W, self.b]\n",
    "\n",
    "    # Forward Propagation\n",
    "        def f_prop(self, x):\n",
    "            self.z = self.function(T.dot(x, self.W) + self.b)\n",
    "            return self.z\n",
    "        \n",
    "        def get_mask(self):\n",
    "            a = np.random.rand(self.out_dim) < self.possibility\n",
    "            return a*np.float32(1.0)\n",
    "        \n",
    "\n",
    "    def build_shared_zeros(shape, name):\n",
    "\n",
    "        return theano.shared(value=np.zeros(shape, dtype=theano.config.floatX), \n",
    "                             name=name, borrow=True)\n",
    "\n",
    "    # Optimizer\n",
    "    class Adam:\n",
    "        def __init__(self, params, alpha=0.001, beta1=0.9, beta2=0.999, eps=1e-8, gamma=1-1e-8):\n",
    "            self.alpha = alpha\n",
    "            self.b1 = beta1\n",
    "            self.b2 = beta2\n",
    "            self.gamma = gamma\n",
    "            self.t = theano.shared(np.float32(1))\n",
    "            self.eps = eps\n",
    "\n",
    "            self.ms = [build_shared_zeros(t.shape.eval(), 'm') for t in params]\n",
    "            self.vs = [build_shared_zeros(t.shape.eval(), 'v') for t in params]\n",
    "        \n",
    "        def updates(self, g_params, cost):\n",
    "            self.b1_t = self.b1 * self.gamma ** (self.t - 1)\n",
    "            self.updates = OrderedDict()\n",
    "            for m, v, param, g_param in zip(self.ms, self.vs, params, g_params):\n",
    "                _m = self.b1_t * m + (1 - self.b1_t) * g_param\n",
    "                _v = self.b2 * v + (1 - self.b2) * g_param ** 2\n",
    "\n",
    "                m_hat = _m / (1 - self.b1 ** self.t)\n",
    "                v_hat = _v / (1 - self.b2 ** self.t)\n",
    "\n",
    "                self.updates[param] = param - self.alpha*m_hat / (T.sqrt(v_hat) + self.eps)\n",
    "                self.updates[m] = _m\n",
    "                self.updates[v] = _v\n",
    "            self.updates[self.t] = self.t + 1.0\n",
    "\n",
    "            return self.updates\n",
    "    \n",
    "    activation = T.nnet.relu\n",
    "    \n",
    "    layers = [                             # (チャネル数)x(縦の次元数)x(横の次元数)\n",
    "        Conv((20, 1, 5, 5), activation),   # 1x28x28  -> 20x24x24\n",
    "        Pooling((2, 2)),                   # 20x24x24 -> 20x12x12\n",
    "        Conv((50, 20, 5, 5), activation),  # 20x12x12 -> 50x 8x 8\n",
    "        Pooling((2, 2)),                   # 50x 8x 8 -> 50x 4x 4\n",
    "        Flatten(2),\n",
    "        Layer(4*4*50, 500, T.nnet.sigmoid, 0.80),\n",
    "        Layer(500, 10, T.nnet.softmax, 1.00)\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    x = T.ftensor4('x')\n",
    "    t = T.imatrix('t')\n",
    "    \n",
    "    params = []\n",
    "    layer_out = x\n",
    "\n",
    "    for (i, layer) in enumerate(layers):\n",
    "        params += layer.params\n",
    "        if i < 5:\n",
    "            layer_out = layer.f_prop(layer_out)\n",
    "        else:\n",
    "            layer.mask = layer.get_mask()\n",
    "            layer_out = layer.f_prop(layer_out)*layer.mask\n",
    "    y = layers[-1].z\n",
    "\n",
    "    cost = T.mean(T.nnet.categorical_crossentropy(y, t))\n",
    "    \n",
    "    g_params = T.grad(cost, params)\n",
    "    updates = Adam(params=params).updates(g_params, cost=cost) \n",
    "\n",
    "        \n",
    "    train = theano.function(inputs=[x, t], outputs=cost, updates=updates,\n",
    "                        allow_input_downcast=True, name='train')\n",
    "    valid = theano.function(inputs=[x, t], outputs=[cost, T.argmax(y, axis=1)],\n",
    "                        allow_input_downcast=True, name='valid')\n",
    "    test = theano.function(inputs=[x], outputs=T.argmax(y, axis=1), name='test')\n",
    "    \n",
    "    \n",
    "    \n",
    "    batch_size = 100\n",
    "    n_batches = train_X.shape[0]//batch_size\n",
    "    epoch = 0\n",
    "    while time.time() - start_time < 45*60 and epoch < 400:\n",
    "        epoch += 1\n",
    "        train_X, train_y = shuffle(train_X, train_y)\n",
    "        for i in range(n_batches):\n",
    "            start = i*batch_size\n",
    "            end = start + batch_size\n",
    "            train(train_X[start:end], train_y[start:end])\n",
    "        #print(epoch)\n",
    "        valid_cost, pred_y = valid(valid_X, valid_y)\n",
    "        if epoch % 50 == 9:\n",
    "            print('EPOCH:: %i, Validation cost: %.3f, Validation F1: %.3f' %\n",
    "                  (epoch + 1, valid_cost,\n",
    "                   f1_score(np.argmax(valid_y, axis=1).astype('int32'), pred_y,\n",
    "                            average='macro')))\n",
    "    pred_y  = test(test_X)\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "ilect": {
     "course_id": 4,
     "course_rank": 7,
     "is_evaluation": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 10, Validation cost: 0.254, Validation F1: 0.937\n",
      "EPOCH:: 60, Validation cost: 0.089, Validation F1: 0.981\n",
      "EPOCH:: 110, Validation cost: 0.084, Validation F1: 0.981\n",
      "EPOCH:: 160, Validation cost: 0.083, Validation F1: 0.977\n",
      "EPOCH:: 210, Validation cost: 0.083, Validation F1: 0.975\n",
      "EPOCH:: 260, Validation cost: 0.084, Validation F1: 0.975\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "def load_mnist():\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                               mnist.target.astype('int32'),\n",
    "                               random_state=42)\n",
    "\n",
    "    mnist_X = mnist_X / 255.0\n",
    "\n",
    "    train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42)\n",
    "\n",
    "    return (train_X, test_X, train_y, test_y)\n",
    "\n",
    "\n",
    "def check_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "\n",
    "    # validate for small dataset\n",
    "    train_X_mini = train_X[:1000]\n",
    "    train_y_mini = train_y[:1000]\n",
    "    test_X_mini = test_X[:1000]\n",
    "    test_y_mini = test_y[:1000]\n",
    "\n",
    "    pred_y = homework(train_X_mini, train_y_mini, test_X_mini)\n",
    "    return f1_score(test_y_mini, pred_y, average='macro')\n",
    "\n",
    "if 'homework' in globals():\n",
    "    result = check_homework()\n",
    "\n",
    "    print(\"No Error Occured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                           mnist.target.astype('int32'),\n",
    "                           random_state=42)\n",
    "\n",
    "mnist_X = mnist_X / 255.0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1)\n",
    "a = homework(train_X, train_y, test_X)\n",
    "print(sum(a==test_y)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 10, Validation cost: 0.036, Validation F1: 0.988\n",
      "EPOCH:: 60, Validation cost: 0.039, Validation F1: 0.993\n",
      "EPOCH:: 110, Validation cost: 0.047, Validation F1: 0.992\n",
      "EPOCH:: 160, Validation cost: 0.047, Validation F1: 0.993\n",
      "EPOCH:: 210, Validation cost: 0.050, Validation F1: 0.993\n",
      "EPOCH:: 260, Validation cost: 0.055, Validation F1: 0.992\n",
      "EPOCH:: 310, Validation cost: 0.046, Validation F1: 0.991\n",
      "EPOCH:: 360, Validation cost: 0.050, Validation F1: 0.992\n",
      "EPOCH:: 410, Validation cost: 0.059, Validation F1: 0.993\n",
      "EPOCH:: 460, Validation cost: 0.058, Validation F1: 0.992\n",
      "EPOCH:: 510, Validation cost: 0.065, Validation F1: 0.991\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                           mnist.target.astype('int32'),\n",
    "                           random_state=42)\n",
    "\n",
    "mnist_X = mnist_X / 255.0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=22)\n",
    "a = homework(train_X, train_y, test_X)\n",
    "print(sum(a==test_y)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '1564' (I am process '4302')\n",
      "Using gpu device 0: GRID K520 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 4007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 10, Validation cost: 0.029, Validation F1: 0.991\n",
      "EPOCH:: 20, Validation cost: 0.032, Validation F1: 0.993\n",
      "EPOCH:: 30, Validation cost: 0.031, Validation F1: 0.993\n",
      "EPOCH:: 40, Validation cost: 0.033, Validation F1: 0.993\n",
      "EPOCH:: 50, Validation cost: 0.038, Validation F1: 0.994\n",
      "EPOCH:: 60, Validation cost: 0.041, Validation F1: 0.994\n",
      "EPOCH:: 70, Validation cost: 0.041, Validation F1: 0.994\n",
      "EPOCH:: 80, Validation cost: 0.041, Validation F1: 0.994\n",
      "EPOCH:: 90, Validation cost: 0.042, Validation F1: 0.994\n",
      "EPOCH:: 100, Validation cost: 0.044, Validation F1: 0.993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 8, 5, ..., 0, 5, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                           mnist.target.astype('int32'),\n",
    "                           random_state=123)\n",
    "\n",
    "mnist_X = mnist_X / 255.0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=22)\n",
    "import time\n",
    "start = time.time()\n",
    "while "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Conv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d289e0ed5c6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m layers1 = [                             \n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;31m# 1x28x28  -> 30x26x26\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mPooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m                   \u001b[1;31m# 30x26x26 -> 30x13x13\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 20x13x13 -> 50x12x12\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 50x12x12 -> 40x 8x 8\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Conv' is not defined"
     ]
    }
   ],
   "source": [
    "    layers1 = [                             \n",
    "        Conv((30, 1, 3, 3), activation),   # 1x28x28  -> 30x26x26\n",
    "        Pooling((2, 2)),                   # 30x26x26 -> 30x13x13\n",
    "        Conv((50, 30, 2, 2), activation),  # 20x13x13 -> 50x12x12\n",
    "        Conv((40, 50, 5, 5), activation),  # 50x12x12 -> 40x 8x 8\n",
    "        Pooling((2, 2)),                   # 40x 8x 8 -> 40x 4x 4\n",
    "        Flatten(2),\n",
    "        Layer(4*4*40, 400, activation),\n",
    "        Layer(400, 10, T.nnet.softmax)\n",
    "    ]\n",
    "    \n",
    "    layers2 = [                            \n",
    "        Conv((20, 1, 9, 9), activation),   # 1x28x28  -> 20x20x20\n",
    "        Pooling((2, 2)),                   # 20x20x20 -> 20x10x10\n",
    "        Conv((50, 20, 3, 3), activation),  # 20x10x10 -> 50x 8x 8\n",
    "        Pooling((2, 2)),                   # 50x 8x 8 -> 50x 4x 4\n",
    "        Flatten(2),\n",
    "        Layer(4*4*50, 500, activation),\n",
    "        Layer(500, 10, T.nnet.softmax)\n",
    "    ]\n",
    "    \n",
    "    if result[0] == result[1] or result[0] == result[2]:\n",
    "        y = result[0]\n",
    "    elif result[1] == result[2]:\n",
    "        y = result[1]\n",
    "    else:\n",
    "        y = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 10, Validation cost: 0.035, Validation F1: 0.991\n",
      "EPOCH:: 20, Validation cost: 0.031, Validation F1: 0.993\n",
      "EPOCH:: 30, Validation cost: 0.037, Validation F1: 0.993\n",
      "EPOCH:: 40, Validation cost: 0.045, Validation F1: 0.994\n",
      "EPOCH:: 50, Validation cost: 0.048, Validation F1: 0.993\n",
      "0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 8, 5, ..., 0, 5, 8])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                           mnist.target.astype('int32'),\n",
    "                           random_state=123)\n",
    "\n",
    "mnist_X = mnist_X / 255.0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=22)\n",
    "homework(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 10, Validation cost: 0.028, Validation F1: 0.991\n",
      "EPOCH:: 20, Validation cost: 0.027, Validation F1: 0.993\n",
      "EPOCH:: 30, Validation cost: 0.031, Validation F1: 0.993\n",
      "EPOCH:: 40, Validation cost: 0.035, Validation F1: 0.993\n",
      "EPOCH:: 50, Validation cost: 0.039, Validation F1: 0.993\n",
      "0.991285714286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 8, 5, ..., 0, 5, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                           mnist.target.astype('int32'),\n",
    "                           random_state=123)\n",
    "\n",
    "mnist_X = mnist_X / 255.0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=22)\n",
    "homework(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3] [1, 2] [1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a  = np.array([[1,2,3],[1,2],[1]])\n",
    "arr_1 = np.array([[1]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-e1b94254a574>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "print(sum(a==test_y)/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorVariable' object has no attribute 'get_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8dc571106bd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'TensorVariable' object has no attribute 'get_value'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "a = theano.shared(np.array([[1,2,3,4]]), name = 'a')\n",
    "b = theano.shared(np.array([[1,2,3,4]]), name = 'b')\n",
    "x = (a+b).copy()\n",
    "print(x.get_value(), a.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
